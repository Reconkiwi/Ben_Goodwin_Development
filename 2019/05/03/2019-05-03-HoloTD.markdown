---
layout: post
title: Mixed Reality Tower Defence - Y3S2
img: "./assets/holotdcoverimg.png"
---

<div style="color: #313639;">
The mixed reality tower defence was a prototype built using Unity3D for Microsoft's HoloLens. The prototype included two tower types, voice recognition, hand gestures and editable waves.
</div>


<div class="single-post-header" style="background-color: #ec3b83; margin-bottom: 10vh;">
<iframe width="460" height="315" src="https://www.youtube.com/embed/9sD3ZXzgsp0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<h1 class="post_title" style="text-align: center; color: #eee9e9;">Mixed Reality Tower Defence - Y3S2</h1>
</div>

<h3 class="single-post-sub-head">The Brief</h3>

###### During this semester we were required to organise or create our own briefs to complete over a 12 week period. This semester, I wanted to test my development skills in an area of industry that I had a key interest in pursuing as well as working on something that I would really enjoy. I decided to focus my development work on something interactive, therefore, I chose to build a project using one of the game engines such as Unity3D or Unreal.

###### About a year ago, I worked on a project named "Heartbeat". It was an interactive HoloLens experience about the functions of the heart and the processes that happen within it. As i hadn't picked up the HoloLens since then, I decided it would be fun to work on one last project with it before I finished university.

###### As I had worked on a educational experience using the HoloLens before, I decided that I wanted to build something a little more fun and interactive. For this reason, I decided to build a game for it. Because of this, I chose to work with the Unity3D game engine as you can build directly for HoloLens with it using Visual Studio. More on that later!

<h2 class="single-post-sub-head">So why Develop for HoloLens?</h2>

###### Having undertaken some research into the potential for emerging technologies in the future, it is suggested that technologies such as augmented and mixed reality will only grow in implementation statistics. In 2017 Gartner predicted that 100 million customers will shop using augmented reality. To back this theory up Apple, have released their new web reality named quick view AR in the last year which has easy implementation into any online store as long as the customer has an iPhone.

###### Similarly, Medivis, Microsoft's technology partner has just announced that it's investors have pledged $2.3 million to help fund the HoloLens 2's surgical platform. This highlights that Microsoft have made massive leaps in the mixed reality market.

###### The market for this technology only seems to be growing in the current climate which made for a perfect excuse to attempt to focus my skills further in the development of applications for these devices.

<h2 class="single-post-sub-head">My Specifications</h2>
* A game
- Consistent design
+ Unity3D
- Look eye-catching
+ Simple to use
- Interactive
+ Immersive
- Built for HoloLens

###### Once I had specified my aims for the project i began looking into the target audiences that I wanted to reach with my product so that I could have a better idea of what I should attempt to build.


<h2 class="single-post-sub-head">Target Audience</h2>

### Industry Professionals

###### Firstly, as I was coming towards the end of my studies at the University of Winchester, it was important that my final project was focussed towards professionals in the industry that I wish to work in in the future. Therefore, the project needed to be impressive, polished and show off a wide range of skills.

### Attendees of the End of Year show

###### Secondly, I was aware that I needed to present my final project at the universities annual end of year show. As the attendance would be a mix of professionals, students and passersby, it was important that the project no only wowed the users but was also really easy to 'pick up and play' as some people would not have much time to take part in the interactive experience and others would need teaching on how to use the device.

### The Lecturers

###### Finally, the project had to show three years worth of growth to the Lecturers as they would be grading it based on the knowledge I had gained and skills I had learnt.

<h3 class="single-post-sub-head">Brainstorming and Ideas</h3>

###### Having worked out my target audience, it was time to undergo some brainstorming to find the perfect project for this semester.

<h3 class="single-post-sub-head">Idea 1: Holo Music Visualiser</h3>

![Holo Visualiser](https://metrik.space/assets/musicvis.jpg)

###### The mixed reality music visualiser was an idea I came up with that would essentially create a floating orb in a real world surrounding using the HoloLens that morphed its shape to the BPM (beats per minute) of a song. The idea was really simple and would have been really fun to work on.

<h3 class="single-post-sub-head">Problems with Idea 1</h3>

###### The problem with the visualiser, however, was that it would have required a lot of 3D animating and modelling to create the effect that I required. As well as this, I was unsure of the scalability of the project from a development point of view. Once the hologram was moving in time to the song there was little that I would be able to add to grow the project further.

<h3 class="single-post-sub-head">Idea 2: Holo board Game</h3>

![HoloLens Board Game](https://metrik.space/assets/holoboard.jpg)

###### The second idea that I had was to develop a HoloLens board game that implemented Vuforia's image tracking to combine digital and traditional gaming. This would give the effect of physical cards and boards coming to life through the use of image tracking.

###### The system for the board game would be very simple with one player attacking and the other defending. The defender would have to place down physical barrier over the board such as walls and trees to try and stop the attacker from reaching their base. The idea would have been simple yet effective.

<h3 class="single-post-sub-head">Problems with Idea 2</h3>

###### The problems with this idea was working out how to trigger events between the attacker and the defender as the game progressed. As well as this I would need to work out whether these events would be completed using traditional methods such as dice rolls or digital ones such as attack buttons and animations within the HoloLens.

<h3 class="single-post-sub-head">Idea 3: HoloLens Card Game</h3>

![HoloLens Card Game](https://metrik.space/assets/holocard.jpeg)

###### Also utilising Vuforia's HoloLens integration, my third idea was to create a card game that projected Holograms out of the cards much like in the animated series of 'Yu-Gi-Oh!'. Once the cards had been placed, the HoloLens would handle the attack and defence events causing the holograms to animate depending on the attack or move that they were doing.

<h3 class="single-post-sub-head">Problems with Idea 3</h3>

###### The main issue with this idea, once again, was the heavy aspect on design. To create a playable card game I would need to design between 20-30 3D models with various animations which seemed unfeasible.

<h2 class="single-post-sub-head">The Final Solution</h2>

###### Having received feedback from my class and after further discussion with my lecturer, I decided to pursue my second idea of the HoloLens board game. This was because it required the least amount of design work to create a barebones prototype of the project. This meant that I would be able to focus directly on the functionality of the game rather than messing around with the design aspects on top of it.

<h2 class="single-post-sub-head">Changes to Idea 2</h2>

###### As well as this, I decided to make some amendments to the board game. Firstly, the game would be single player and the user would place objects in the way of the 'AI' attacker to stop it reaching the defenders base. Secondly, the game would no longer require event triggers or event cards as the mechanics of the game had become far more simplified.

<h2 class="single-post-sub-head">The Breakdown</h2>

* Setup the HoloLens development environment
- Setup the HoloToolkit
+ Setup Vuforia
- Image track a holographic board to a physical board
+ Spawn an enemy from an image that navigates to a defender tile
- Create objects that block the enemies path

###### Having come up with the idea for my project I decided to breakdown each section of it so that I could work out how best to manage my time.

<h2 class="single-post-sub-head">Organisation and Timeline</h2>

###### To organise my time precisely I created a set of development stages that I could work towards each week. I had around 12 weeks to complete this project before the end of year show so I set myself 12 development stages.

<h3 class="single-post-sub-head">Development Stages</h3>

* Stage 1: Define final project idea
- Stage 2: Setup HoloLens development platform (SDK' and packages)
+ Stage 3: Image track digital board to physical board
- Stage 4: Create enemy pathfinding using Unity navigation
+ Stage 5: Image track impassable objects
- Stage 6: Create enemy spawner
+ Stage 7: Victory and defeat circumstances
- Stage 8: User testing
+ Stage 9: Bug fixing
- Stage 10: Final amendments
+ Stage 11: Final critique before end of year show and last minute Changes
- Stage 12: Present at the end of year show

<h2 class="single-post-sub-head">Personal Goals</h2>

* Strengthen Unity3D skills
- Create an exciting prototype
+ Learn Vuforia
- Strengthen interactive/game portfolio projects
+ Finish the prototype having learnt new skills
- Complete my second HoloLens project

###### I decided on these personal goals for the project as I felt that I needed to strengthen my skills within the game industry, where I eventually wish to pursue a career. As well as this I have a real interest in emerging technologies such as mixed and augmented reality so having these goals gave me the chance to pursue the development of applications for them.

###### Also, I have been writing my dissertation on the efficiency of emerging technologies so it was really interesting to see first hand the potential that they had.

<h2 class="single-post-sub-head">Personal Gantt Chart</h2>

###### I also chose to create a gantt chart to help myself stick to my deadlines:

![TeamWeek](https://metrik.space/assets/hologamegantt.png)

###### Unfortunately, due to development issues (more on those later) I was unable to stick completely to the plan that I had set myself. Luckily, however, I had set myself a contingency plan in case this happened.

<h2 class="single-post-sub-head">Development Tools</h2>

###### To gain a better understanding of the development process, I briefly researched into the tools that I would be using for development:

<h3 class="single-post-sub-head">Unity3D</h3>

![unity](https://metrik.space/assets/unity3d.jpg)

###### Unity is a cross-platform real-time engine used for various game and interactive applications. Unity has a partnership with Microsoft which means that setup and development for HoloLens using this software is extremely well documented. Microsoft also suggests Unity3D as the software to use directly for Holo development and includes the HoloToolkit and mixed reality toolkit packages for quick scene setups.

###### As well as this you can install development packages to Unity that allow you to build directly for Windows platforms app/store. This means that you can choose the exact device you wish to build for e.g. the HoloLens.

![unity](https://metrik.space/assets/buildforholo.png)

###### Once this has been done you can simply open up the built application in visual studio and then run the program either through the HoloLens emulator or the device itself.

###### Using Unity3D was an imperative tool for the development of my application and in my opinion a better choice that Unreal or any other engine for this style of application due to the resources and documentation available.

<h3 class="single-post-sub-head">Vuforia</h3>

![unity](https://metrik.space/assets/vuforia.png)

###### Vuforia was another important tool for the development of this application. Vuforia is an augmented reality software development kit (SDK) that allows devices to track image targets and then place holograms above them. The SDK, in recent years, has increased its capabilities to the HoloLens and other mixed reality headsets, allowing for developers to track images within these devices.

![unity](https://metrik.space/assets/vuforiatrackingexample.jpg)

###### To get the effect of merging physical traditional boardgames with the digital world, I needed to implement Vuforia into my application so that I could track the blank physical board and project a hologram of my own board on to it through the HoloLens. As well as this, the impassable objects that I wished to put in front of the attacker required their own images to be tracked to create the effect of placing down physical cards or tiles.

<h3 class="single-post-sub-head">HoloToolkit</h3>

![unity](https://metrik.space/assets/holotoolkit.jpg)

###### Another important tool that i needed for development was the HoloToolkit. The HoloToolkit is a Unity package that includes all of the necessary prefabs, scrips and libraries to include mixed reality features to an application such as gaze controls, hand gestures, spatial mapping and voice recognition.

###### Although, Microsoft suggests using the MixedrealityToolkit (MRTK) I personally learnt to develop Holo applications using the HoloToolkit so I felt more comfortable using this package instead. The MRTK, however, does get updated more frequently so it is likely that I will need to use that instead for future projects.

<h3 class="single-post-sub-head">Visual Studio</h3>

![unity](https://metrik.space/assets/visualstudio.png)

###### Visual Studio is an integrated development environment (IDE) made by Microsoft. It can be used for various development projects such as computer programs, websites, web apps, web services and platforms. As well as this Visual Studio uses Microsofts development platforms such as Windows Store, API, Foundation and Silverlight.

###### The most important information to take from this, however, is that Visual Studio can be used directly to build Windows Universal applications for various devices such as Microsoft's HoloLens. As well as this you can use Visual Studio to emulate the HoloLens through your computer. Although, it requires Hyper-V to be enabled on your computer to make use of this feature which is only available on Windows Professional.


<h2 class="single-post-sub-head">Development</h2>

###### Once I had researched and outlined the tools that I required to get my HoloLens application up and running, it was time to begin developing my first prototype. First though, I needed to setup all of the SDK's and packages for development.

<h3 class="single-post-sub-head">Installing the Tools</h3>

###### Having worked on Holo applications before, I was able to setup the tools I needed fairly quickly, although, they needed a fresh install as I had recently wiped my Windows PC. Luckily, Microsoft has plenty of documentation regarding how to get started. You can find the information [here.](https://docs.microsoft.com/en-us/windows/mixed-reality/install-the-tools)

###### The tools that I needed or needed to install were as follows:

* Windows 10 with developer mode activated
- Visual Studio 2017 with C++ and Universal Windows Development workloads
+ Windows SDK Insider Preview 18362
- Unity3D

### Enabling Developer Mode

![developer mode](https://metrik.space/assets/enabledevelopermodepc.png)

###### Developer mode is extremely easy to setup. On your navigate to Settings > Update & Security > For developers and enable developer mode. This may take a few minutes to install the packages.

### Visual Studio Workloads

![developer mode](https://metrik.space/assets/workloads.png)

###### Once Visual Studio is installed, you are able to modify its setting and add additional workloads/components. The Universal Windows Platform and C++ development workloads are really easy to find and install here. It should be noted that these files are quite heavy on disk space.

### Windows SDK's

###### The Window's SDK can usually be installed with Visual Studio, however, I had a few complications with mine which meant that I needed to do a manual install

### Unity Packages

###### When installing Unity ensure that the Universal Windows Platform component is checked otherwise it needs to be installed manually before Unity will let you build apps for the HoloLens

<h3 class="single-post-sub-head">Setting up the Unity Scene</h3>

![developer mode](https://metrik.space/assets/vuforiaholo.png)

###### I began development by importing Vuforia's HoloLens package from the Unity asset store. It contained loads of example scenes such as image targeting to help you get started. I decided to wipe all of the content from one of the scenes aside from the camera and scene setups to save development time, however, I will go through the important features to include when setting up from scratch.

### Camera Setup

![developer mode](https://metrik.space/assets/ARCamera.png)

###### To begin with, locate the AR Camera prefab within the assets folder and drag it into the scene. Ensure the scene is empty within the hierarchy tab before you do this.

###### Click on the camera in the hierarchy and ensure that 'clear flags' is set to solid colour and that the colour is black. Unlike immersive headsets the HoloLens needs to capture the real world so we switch the camera from skybox to solid colour as the HoloLens renders this as transparent. As well as this, ensure that under 'Clipping Planes' the 'Near' setting is set to 0.85 as the HoloLens will not render anything close to this.

### Setting up Vuforia for Digital Eyewear

![developer mode](https://metrik.space/assets/vuforiaconfig1.png)

###### Once the camera is set up, it is important that we set up the configure Vuforia to run on the HoloLens. This is very simple to do. Navigate to Window > Vuforia Configuration. This will open up a configuration panel in the inspector. Once this is done, simply set the 'device type' to digital eyewear and proceed to set the 'device config' to HoloLens.

###### SIDE NOTE: If you plan on using world anchors for your project (this means that the HoloLens will remember the position of your model) then enable 'Track Device Pose' inside of the Vuforia Configuration panel and set the 'Tracking Mode' to positional. This is something that I failed to realise for quite a long time and caused me multiple problems throughout development as the models kept failing to track properly!

### Setting up Player and Project Settings

![developer mode](https://metrik.space/assets/playerquality.png)

###### To edit the project, player and quality settings, we need to navigate to edit > project settings. From there if we access the quality tab we need to ensure that the quality is set to 'fastest' this will help to reduce latency on the HoloLens.

###### Having done this, Microsoft also has recommended settings in their documentation which can be viewed [here.](https://docs.microsoft.com/en-us/windows/mixed-reality/recommended-settings-for-unity) Navigate to > Player > XR Settings within project settings. Select 'Single Pass Instanced' from the Stereo Rendering Method. It should be noted that 'Virtual Reality Supported' must be enabled. As well as this enable 'Depth Buffer Sharing' in the XR settings.

###### Once this was completed, I scrolled up to 'Publishing Settings' and navigated to capabilities within the Player tab. This is where Unity tells the application which features to enable. For this project i enabled 'Spatial Perception', 'Microphone' and 'Webcam'.

### We are setup for development!

<h3 class="single-post-sub-head">Image Tracking</h3>

![developer mode](https://metrik.space/assets/creategameobjimagetreack.png)

###### To begin with I navigated to Gameobject > VuforiaEngine > Image to create an image target for my game board to track to. However, I needed to set up a Vuforia database first before I could track anything! Once again Vuforia has extremely good documentation to help new developers get started quickly. The documentation for Unity can be found [here.](https://library.vuforia.com/articles/Training/getting-started-with-vuforia-in-unity.html) It should also be noted that i had forgotten to install the Unity Vuforia component in the Unity installer, which meant that I had to install it manually. As well as this Vuforia support needed to be enabled in the XR settings panel which i had also forgotten to do.


### Setting up the Vuforia Database

![developer mode](https://metrik.space/assets/Vuforiadevkey.png)

###### To setup the Vuforia database I needed to sign up for a Vuforia development account and then add a licence key in the 'Licence Manager'. One this was completed, I needed to verify my key inside of the Vuforia configuration under the 'Global' setting.

![developer mode](https://metrik.space/assets/targetmanager.png)

###### After this, I was able to simply add my images to Vuforia's target manager. It was important that I tried to keep the tracking quality as high as possible to ensure that the HoloLens could easily find and track the image without any latency or jumpiness. From the Image above it can be seen that I initially used a one star image quality target in an attempt to track the board. This made it extremely difficult to render the holographic board above the image, thus, I needed to find a more complex image/pattern to track.

###### Once the image targets had been setup, the target manager will allow you to download the database as a Unity package which can be simply opened to compile it into your Unity project.

![developer mode](https://metrik.space/assets/imagetrackingsetup.png)

###### After the database had been imported, I was able to click on the Vuforia image Gameobject (mentioned earlier) in the hierarchy and set it to track a specific image from my database. As seen in the picture above, I have chosen to track the 'tower' card with this Gameobject. After this, I simply added a tower Gameobject to the hierarchy and set it as the child of the Vuforia image Gameobject. This means that whenever Vuforia recognises the tower image, it will generate the hologram of the tower! It should be noted, however, that the hologram will spawn in relation to its distance from the image Gameobject in the Unity scene. Therefore, it is often good practice to ensure that the hologram is directly above the image target unless intended otherwise.


### So we have image tracking down....... now what!?

<h3 class="single-post-sub-head">Enemy Navigation</h3>

###### Having successfully managed to image track my image targets inside the HoloLens, it was time to work out how I would best go about creating an AI enemy to navigate towards a specific location. Having discussed a few possibilities with my lecturer, I decided to settle on attempting to implement Unity's inbuilt navigation and pathfinding.

###### As I have worked on HoloLens projects before, I knew that I often found it more beneficial to test specific mechanics in separate Unity projects to avoid any of my code rolling over or accidentally manipulating some of my other scripts. I decided to learn the basics of navigation and pathfinding inside of a very basic Unity scene.

###### The documentation for Unity's navigation and pathfinding can be found [here.](https://docs.unity3d.com/Manual/Navigation.html)

![developer mode](https://metrik.space/assets/pathfindandnavbasescene.png)

### Navigation and Pathfinding Basics

### Unity navigation is made up of three main components:

* Navmesh
- Navmesh agent
+ The pathfinding script

###### Firstly, I needed to open the navigation window within Unity. This can be found by navigating to Window > AI > Navigation. Once this has been completed a window will appear with the options Agents, Areas, Bake and Object. After this, I needed to create my ground plane and wall Gameobjects. Having done this, I clicked both of them and navigated to the 'Object' panel in the Navigation window. From here, I needed to se the 'Mesh Renderer' to 'Navigation Static'. This defines to Unity's inbuilt navigation that these objects are available to be navigated through.

![developer mode](https://metrik.space/assets/navmeshbakingtest.png)

###### After this, I navigated to the 'Bake' panel and hit bake. Above is the result of this. Inside of the bake panel, there and many options that you are able to change such as agent radius, height, max slope and step height. These can help to alter the pathfinding ability of your Navmesh agents e.g. whether they can climb a specific slope or jump over a specific wall. As I was working with flat surfaces, I didn't really need to touch on these at all. As seen from the image, baking the navmesh defines the areas that the NavmeshAgent can move through. As the wall is above the maximum slope height, the Navmesh bakes around the wall defining that the agent will not be able to move through it.

### Creating Enemy pathfinding

![developer mode](https://metrik.space/assets/navmeshagentsetup.png)

###### The next step was to create an 'enemy' Gameobject and a 'target' Gameobject. For testing mine were defined by two cubes of different colours. Once this had been done, I added the 'Nav Mesh Agent' component to my 'enemy'. This simply defines to the Navigation system that my 'enemy' Gameobject is an agent and that it can move across the Navmesh. Inside of the 'Nav Mesh Agent' component you are able to change various mechanics such as speed, angular speed and obstacle avoidance properties. Once again, as I was working with a very simple scene, I left these alone for the time being.

### Lets write some code!

![developer mode](https://metrik.space/assets/movetheagenttest.png)

###### I created a simple script that in short tells the agent to move towards a destination. I created a serialised field that allowed me to set the target destination of the enemy. This meant that I could simply drag and drop the 'target' Gameobject into the serialised field and set it as the target destination.

![developer mode](https://metrik.space/assets/destination.png)

###### After this, I found the NavMeshAgent component from 'this' (the Gameobject that this script is attached too) and set its name to -navMeshAgent. Once the NavMeshAgent is defined, I ran an if statement inside of the Update function (called once per frame) which checks to see whether or not a destination has been defined. If it has, the target vector is set to the destination and the NavMeshAgent sets its destination to the target. Here is the result of my code below:

{% raw %}
<iframe width="560" height="315" src="https://www.youtube.com/embed/lyOOBTSqarQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
{% endraw %}

### Combining Pathfinding with Vuforia

###### I began compiling the scripts and assets from the navmesh testing scene and implemented them into the Vuforia project that I had started. As I hoped, I was able to bake a navmesh onto my holographic board which I had hoped would allow my enemy to travel to the destination that I had set in AR. Unfortunately, this did not work quite how I had imagined.

###### As the navmesh baked before the game had begun, I believe that the navmesh instantiated at the same distance from the camera in comparison to that in the inspector. This meant that the agent would teleport to this world location and away from the image tracked board.

###### I began researching ways to fix this problem, however, I found little information as nobody seemed to be using navmeshing in AR or MR. Eventually, I was able to find a Unity tutorial on creating NavMesh Surfaces during runtime.

###### You can find the tutorial [here.](https://unity3d.com/learn/tutorials/topics/navigation/baking-navmesh-runtime)

### Fixing the NavMesh Problem!

###### I imported four scripts from the Unity tutorial found above. These included the Navmesh Link, Navmesh Modifier, NavMesh Surface and NavMesh Modifier Volume. I attached the Navmesh Surface script to my board and then created a simple spawner and surface builder script. I will discuss the spawning section of the script after this.

![developer mode](https://metrik.space/assets/navmeshsurfacescript.png)

###### As shown in the tutorial, i created an array of surfaces that I needed to include in my NavMesh. On 'Start' the script simply looks for the number of surfaces in the array and creates a NavMesh on each surface. The result looked like this:

{% raw %}
<iframe width="560" height="315" src="https://www.youtube.com/embed/WH7i9twg03E" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
{% endraw %}

### OOOOOOOH THAT'S A LOT OF LATENCY

###### I began testing my build settings in an attempt to reduce latency problems. I found that setting the texture quality to 'eight res' removed the latency from the game and didn't compromise the quality of the image. I decided to push this further and add a few more textures and polygons to stress test the game. Here were the results:

{% raw %}
<iframe width="560" height="315" src="https://www.youtube.com/embed/_VggyzAAvDU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
{% endraw %}

###### As seen above, the latency was better than previously. Even with the larger polgon and texture count. However, i was a little worried about the amount of time that it was taking to register the image target. I decided to ignore that for the time being a start on creating an enemy spawner.

### This is where my idea changed a little

###### I decided that there was a potential for me to build a slightly more interactive project than I had previously planned. I decided to attempt to make a prototype for a mixed reality tower defence game where the user would place tiles of towers to defend their base from incoming waves of enemies.

### Back to enemy spawning!

###### I began by converting my enemy Gameobject into a prefab that I could call and spawn multiple of.

![developer mode](https://metrik.space/assets/enemyprefab.png)

###### Having done this, I need to create a script that instantiated the NavMesh Agent:

![developer mode](https://metrik.space/assets/navmeshagentspawn.png)

###### To ensure that I was able to create this script efficiently, I was required to use specific Unity libraries. I chose to use the Unity AI library for NacMesh agent settings/destination settings whereas the Windows Speech library was needed to add voice recognition into the game. This was used to tell the game when to begin a round.

###### Before the Start() function, I defined public variables for the enemy prefab, begin wave voice command and agent destination. This meant that I would be able to edit these variables within the Unity inspector or drag Gameobjects into the destination and enemy prefab fields. Inside of the Start() function, I created a keyword recogniser which used the the begin command string as reference for the voice command I wanted Unity to listen out for.

###### After this, a keyword recogniser function gets called which essentially waits for the keyword(s) to be called and then completes an action. In this instance, the action called was the SpawnAgent() function. Inside of this function, the attacker prefab is instantiated and transformed to the position of the spawner. Once this has completed, Unity locates destination inside of the GameObjects AttackerMove script, sets it as the goal and then moves towards it. Finally, SpawnAgent is invoked continuously at a random range between two variables. This creates a constant stream of enemies rather than waves, however, this was used to stress test the project on the HoloLens to ensure there was no latency.

### BUT THERE WAS LOADS OF LATENCY!

###### During a user testing session, it was found that the latency became severely worse with the implementation of more GameObjects to a point where the game became unplayable. As well as this, the board tracking was becoming more unstable than previously, even with world anchors, which added to the severity of the latency.

### IT WAS TIME TO COME UP WITH A DRASTIC SOLUTION

<h3 class="single-post-sub-head">Rebuilding the Game Without Vuforia</h3>

###### The decision to remove Vuforia from the application was a difficult decision as it meant that I would need to entirely rebuild the application from scratch in the space of about four weeks before the end of year show. However, from personal experience, I have never received notable latency when working on HoloLens applications without Vuforia. Therefore, I believed the problem to be entirely Vuforia related. This was not the definitive reason for the cause of the latency, however, I was willing to take a risk by rebuilding the application without it.

<h3 class="single-post-sub-head">Saving as Much Time as Possible</h3>

###### To get started quickly on the redevelopment of my application, I decided to strip down one of my already existing Unity HoloLens projects (Heartbeat) so that my scene would be setup ready with the HoloToolkit, camera and project settings. This reduced development time significantly and allowed me to focus on retrieving as many of my original assets as possible. Aside from the board itself, most of the assets and scripts were easy to transport into the new Unity project.

### The NavMesh Problem!

###### Once again the NavMesh spawning caused major problems when reacting with the HoloToolkit. For some reason, the NavMesh surfaces code would entirely ignore the surfaces thatI was trying to target and simply create a mesh the size of the room that I was standing in. This meant that the enemies would not spawn as or move as the spawner was too far away from the NavMesh. I attempted to fix this bug, however, I was unable to come up with a solution for it. Therefore, I decided to come up with a new way to spawn and move enemies towards a target location!

<h3 class="single-post-sub-head">Waypointing</h3>

###### Having looked at a series of tower defence tutorials for desktop builds (I could not find anybody that had built one for the HoloLens, however, I will link the tutorials at the end of this as they helped with some of the programming), it seemed clear that developers favoured using waypoints to move their enemy units. I believe this is due to the fact that enemies in this style of game have only ever got to move in one specific route, therefore, if designed correctly, developers do not need to account for enemies colliding with any towers or other terrains as the designated route will already be set.

###### I began by creating a series of empty GameObjects all named 'waypoint' at each point where my enemy would need to change the direction that it was moving in e.g. a corner. The first waypoint being at the start of the map and the last being inside of the castle/defence point. Having done this, I set the waypoints to be visible in the inspector using the gizmo feature inside of the Unity software. The final product looked like this:

![developer mode](https://metrik.space/assets/waypointgizmos.png)

###### I then created a script that simply placed all of the waypoints into an array. This then determined the distance between each waypoint. The code looked like this:

![developer mode](https://metrik.space/assets/waypointparentcode.png)

###### The code creates a static Transform array called points. The reason that it is static rather than private was to ensure that other scripts could easily reference the array externally. Once this is done the script defines the distance between each point.

<h3 class="single-post-sub-head">Rebuilding the AttackerMove script</h3>

###### As the game was no longer NavMesh as a movement ground for the enemy, I needed to re-write my AttackerMove script as my enemy would not have a mesh to move on. The waypointing system was designed to counteract this by setting points for th enemy to move towards. The rewritten script looked like this:

![developer mode](https://metrik.space/assets/moveenemywaypoint.png)

###### Before the Start() function, variables are defined for the enemy speed, target and wavepoint index. The speed float was public so that I was able to edit the enemies speed within the inspector. Inside of the Start() function, the target is set to the static array waypoints and the target is set to 0 of the array.

###### The Update() function then transforms the enemy to the target waypoint by multiplying the enemy speed by time.deltatime. Once the enemy is withing 0.01f of the waypoint, a function is run called GetNextWaypoint(). This initially checks if there are any more waypoints, if there are, it will increase the waypoint number in the array by one, thus. setting a new destination target. If there are no more waypoints available, then the script calls the EndPath() function. The EndPath() function reducaes the players lives by 1 (more on the later) and destroys the enemy GameObject.

 <h3 class="single-post-sub-head">User Testing the New Waypointing System</h3>

###### During the testing phase of my waypointing system, I found that I had set the distance before the waypoint was changed too high. This resulted in the enemies, changing direction much earlier than I wanted them too. I eventually reduced the distance down to 0.0f which I felt left an almost perfect representation of how I wanted the enemies to move. Here is the result:

{% raw %}
<iframe width="560" height="315" src="https://www.youtube.com/embed/z09YcHnDHDA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
{% endraw %}

###### As shown in the video above, the enemy GameObject reaches each waypoint and then changes direction. If I were to have more time, I would have liked to include some sort of object collision script which would have helped stop the enemy from moving through the tower GameObjects. However, I believe that this would have required a different form of movement rather than waypointing.

 <h3 class="single-post-sub-head">Waves</h3>

###### The next stage was to create a wave generator so that I could alter the number of enemies as well as their speed and health stats. I wanted to be able to create waves within the inspector as I felt that this would be an efficient way of quickly building a large number of levels. I began by setting up an array called waves:

![developer mode](https://metrik.space/assets/wavearray.png)

###### As shown above i created a serialisable field called 'Wave' that was filled with various editable properties such as name, count, rate and prefab or 'enemy'. This was then converted into an array called 'Waves' which allowed me to create multiple instances of the Wave field within the inspector. Before the game begins, the Wave is also set to 0 to ensure that the game doesn't start at a random level. The result of this can be shown in the inspector:

![developer mode](https://metrik.space/assets/enemywaves.png)

###### As shown, this form of wave creation allowed me to hand build a series of waves with different enemies, counts and spawn rates which meant that I was able to steadily increase the difficulty of the game each time a new wave was spawned. Something that I did not consider, however, was that the game breaks if multiple waves have the same name. When the Unity reaches one a duplicate wave name, it will automatically reset the wave number to 0. I am not completely sure why this happens, however, I decided to make sure that waves were saved with different names to avoid the bug.  

###### The real difficulty, however, came when I tried to implement voice recognition into the game. As suggested before, I was initially using Unity's windows speech library with the keyword recogniser to create speech recognition. The problem with this was that I was unable to get the recogniser to recognise more than one word or phrase. This meant that I would not be able to create multiple phrases such as wave starting and building towers.

### The Solution!

###### The HoloToolkit luckily came with speech recognition scripts that I could use to easily implement speech recognition iunto my game. This is something that i had never encountered before when developing for HoloLens, but, I found it really simple to setup. Firstly, I added the speech input source script to the the cameras input handler.

![developer mode](https://metrik.space/assets/speechinputsource.png)

###### After this, I simply created three keywords 'Start Wave', 'Build Tower' and 'Build Missile'. These would then be called in the speech input handler (another HoloToolkit script) attached to my game manager GameObject. The result looked like this:

![developer mode](https://metrik.space/assets/speechinputhandler.png)

###### In the inspector side of this script, I selected each keyword and set a function to run every time the keyword was called. When the 'Next Wave' keyword was called the WaveCompleted() function was called.

![developer mode](https://metrik.space/assets/wavecompleted.png)

###### The WaveCompleted() function worked very simply. Firstly, it begins the SpawnAgent coroutine (starts the wave) and then increases the wave count so that the next level begins when the 'Start Wave' keyword is detected. As well as this, the script checks whether there are any more waves within the 'Waves' array. If there are no longer anymore waves, the wave count restarts (the game resets).

 <h3 class="single-post-sub-head">Spawning Waves</h3>

###### Once the WaveCompleted() function is completed, the enemy prefab needs to be instantiated. The SpawnAgent coroutine that is called requires an IEnumerator which defines the 'Wave' as a a variable. After this, the IEnumerator checks the wave count and runs a SpawnEnemy function. Once this has been completed, The SpawnAgent runs the SpawnEnemy function equal to the waves count variable.

###### The SpawnEnemy() function finds the enemy prefab and instantiates it to the spawn position. This is repeated until the IEnumerator has detected that the wave count is 0. The code looks like this:

![developer mode](https://metrik.space/assets/instantiatewave.png)

### The Final Wave Spawn result

###### Finally, I created a series of different cube prefabs of different colours to represent varied enemies with varied speeds and then setup a series of waves using these prefabs with different counts and rates. This was the result:

{% raw %}
 <iframe width="560" height="315" src="https://www.youtube.com/embed/p4fj9glkaMQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
{% endraw %}

 <h3 class="single-post-sub-head">Defining and Displaying Player Stats</h3>

![developer mode](https://metrik.space/assets/playerstats.png)

###### The player stats script simply defines the number of lives and the money that the player starts with. Both of these are static variables as they need to be accessed outside of the player stats script. An example of this can be seen in the AttackerMove script mentioned earlier where the lives are reduced by one when an enemy reaches the final waypoint.

 <h3 class="single-post-sub-head">Player UI</h3>

![developer mode](https://metrik.space/assets/livesui.png)
![developer mode](https://metrik.space/assets/moneyui.png)

###### The user interface scripts are extremely simple. They simply turn the lives and money variables into strings that are displayed on the canvas. This canvas is displayed over the camera i.e. over the view of the HoloLens. This was used to create a visual representation of these variables for the ease of the user. As white is the easiest font colour to see on the HoloLens, i chose to opt for this as well as one of Microsofts suggested fonts. I did have some issues displaying the UI as it appeared differently on the HoloLens than it did on the Unity scene viewer. However, after some tinkering I was able to configure this correctly.

{% raw %}
<iframe width="560" height="315" src="https://www.youtube.com/embed/qK0rguNJce4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
TOWER Spawning
{% endraw %}

{% raw %}
<iframe width="560" height="315" src="https://www.youtube.com/embed/dCE0lN4c7fU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
{% endraw %}

###### The result of which looked like this. The videos show the UI in action with the reduction of lives and money when certain requirements are met. This will be discussed later on!

 <h3 class="single-post-sub-head">Buying Towers</h3>

###### As mentioned earlier, the towers were setup to be bought through the voice command 'Buy Tower' and 'Buy Missile' similarly the the 'Next Wave' command. As both of the tower purchasing command are in essence the same code, I will only discuss the code for the 'Build Tower' command.

![developer mode](https://metrik.space/assets/towerbuysetup.png)

###### The first step was to setup a series of variables that we needed to write the script. Both of the tower types needed to be public as I needed to drag the prefab into the field within the inspector. As for the objcamera, I could have left this private as the camera is found within the script. However, I kept it public for testing to ensure that my camera was being found. I also created a private vector named spawn position, used to deifine where the tower would be instantiated as well as a private integer to help define the distance i wanted spawn position to be from the camera.

![developer mode](https://metrik.space/assets/objcamerafind.png)

###### Inside of the Start() method, I set the objcamera to find the camera with the tag 'Main Camera'. Tags can be set in the inspector which is what I done with my mixed reality camera.

![developer mode](https://metrik.space/assets/buytowerfunction.png)

###### Once the keyword 'Buy Tower' is called, the BuyTower() function is called. I set this up with an if statement that checks whether the player has more or equal to the cost of the tower. If yes, the cost of the tower is subtracted from the overall stats of the player. The spawn position is then set to in front of the camera (depending on the DistanceToCamera variable) and the GameObject is instantiated.

![developer mode](https://metrik.space/assets/towerworth.png)

###### The tower costing works very similar to the player stats, however, it is set up with a public integer so that I was able to change the cost of a tower prefab without having to write a new script for each tower.

###### The buying system works exactly the same with the missile turret, however, responds to the voice command 'Buy Missile'
 <h3 class="single-post-sub-head">Placing Towers and Moving the Board</h3>

{% raw %}
<iframe width="560" height="315" src="https://www.youtube.com/embed/g2MjC8sb19M" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
{% endraw %}

###### Another important factor was to ensure that I added gesture handling to the application so that the user can move the holograms (towers) that it spawns in. Luckily the HoloToolkit comes with an input and gesture handler script already writted. Therefore, i was able to simply add a HandDraggable script to my Gameobjects to get the result seen above. It should be considered, however, that Gameobjects require some sort of mesh for the HandDraggable script to work.

 <h3 class="single-post-sub-head">Tower Targeting</h3>

###### Having setup the tower spawning and movement, I then needed to create a way for the towers to identify enemies and target them.

![developer mode](https://metrik.space/assets/targetsetup.png)

###### Before the start() method, I defined two variables, a public string of the tag 'Enemy' and a Transform called target.

![developer mode](https://metrik.space/assets/updatetargetfunction.png)

###### After this, I created a script that sets the target to find a GameObject with the tag 'Enemy'. The script then finds the nearest GameObject with the tag 'Enemy' and works out whether it is within the towers range variable. If is it, that Enemy becomes the target. If not the script returns null and there is no target enemy. As well as this, I set up a gizmo so that i could see the range og each tower within the inspector for testing purposes. The result looked like this:

![developer mode](https://metrik.space/assets/towerrange.png)

![developer mode](https://metrik.space/assets/towerrangegizmo.png)

###### After some tinkering with the range settings, I managed to reduce the size of the towers range to improve gameplay.

 <h3 class="single-post-sub-head">Tower Shooting</h3>

###### Once the targeting was set up, I needed to make the tower fire projectiles at the target enemy. I created a series of variables that I wanted to be able to edit for each tower prefab:

![developer mode](https://metrik.space/assets/towervariables.png)

![developer mode](https://metrik.space/assets/firerate.png)

###### I then created a simple script that runs a shoot function if the countdown timer is at 0. It then restarts the countdown and repeats. The next stage was to fire a projectile.

![developer mode](https://metrik.space/assets/towershootfunction.png)

###### The tower shoot function simply instantiates a bullet prefab at the fire point of the tower, plays a sound clip and then moves towards the target.

<h3 class="single-post-sub-head">Enemy Health</h3>

![developer mode](https://metrik.space/assets/enemyhealth.png)

###### Before I could implement bullet damage into the game, I needed to setup the health stats of my enemy prefabs. Before the start function variables are setup for health, speed and worth. Once again, these are all public so that i could create multiple prefabs of enemies without changing any of the code. As well as this I created a death animation to play when the enemy dies (more on this later). The damage function is called when the projectile hits the enemy. It simply deducts the bullet damage from the health of the enemy. When the enemies health reaches 0, a death animation is played and the GameObject is destroyed.

###### The death animations were created with Unity's inbuilt particle system. I am a little bit of a novice with this side of Unity, however, as I was only blowing up cubes, I created a really simple cube exploding effect with the material of the prefab I was destroying. The result looked like this:

{% raw %}
<iframe width="560" height="315" src="https://www.youtube.com/embed/JLo9Wdmjp_8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
{% endraw %}

<h3 class="single-post-sub-head">Bullet Seeking and Damage</h3>

![developer mode](https://metrik.space/assets/bulletvariablesandseek.png)

###### To make the bullet move towards the enemy, I needed to set up a series of variables such as speed, damage and radius. After this the script finds the seek function from the tower script and defines the target. After this, the bullet prefab moves towards the target which is affected by the bullet speed. Once the target is hit, it runs a function called HitTarget().

![developer mode](https://metrik.space/assets/hittarget.png)

###### The HitTarget() function plays an animation and then must work out whether the explosion radius is above 0. If it is, it runs the Explode() function, if not, it moves straight to the Damage() function. Once this has been completed the GameObject is destroyed.

###### The Explode() function puts all of the GameObjects with the tag 'Enemy' into an array if they are within the explosion radius. Then, for each enemy it runs the Damage() function.

###### The Damage() function locates the 'Enemy' and sends the damage amount the the Enemy script where the damage is handled.

### Bringing it all together!

###### The videos below will show the results of using an explosion radius of over 0 in comparison to having an explosion radius of 0. The towers have been set up as different prefabs. The tower, and the missile tower which means that they have different speeds, damages and radius' thanks to the editable public variables within the inspector. As well as this each tower has its own sound effect and impact animation.

{% raw %}
<iframe width="560" height="315" src="https://www.youtube.com/embed/0hEbij8MeOA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
{% endraw %}

{% raw %}
<iframe width="560" height="315" src="https://www.youtube.com/embed/0vxt95BpYlo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
{% endraw %}

<h3 class="single-post-sub-head">Victory and Defeat Requirements</h3>

###### The victory and loss system was extremely basic. If I had had more time, I would have liked to implement defeat and victory ui elements into the game with a restart button and potentially a leaderboard too. However, due to the problems encountered with Vuforia in the first half of the semester, my development time was cut short. Therefore, I set up a simple system for victory and loss. When the final wave is completed the game restarts the wave count whereas when  the players lives reach 0 the game will restart entirely.

![developer mode](https://metrik.space/assets/sceneend.png)

###### I used Unity's scene manager library to create a simple script that restarted the active scene when the player reached 0 lives.

<h3 class="single-post-sub-head">User Testing</h3>

###### Although the game was play tested throughout development, I ran two external user testing sessions. One with a group fo friends and one at the end of year show.

### Friends Testing

![developer mode](https://metrik.space/assets/mixedrealitydefence.jpg)

###### The main issue found with user testing was that being able to move the board for the entire game would mean that they would sometimes accidentally move it causing for all of the towers to move out of place. For this reason, i decided to disable the HandDraggable script on the board after the first wave begins.

![developer mode](https://metrik.space/assets/handdraggable.png)

###### Other than this, the only changes that i needed to make were various balancing issues. Reducing certain wave speeds, count and rates as well as reducing the worth of a lot of unity.

### Friends Testing

###### The game was also tested at the end of year show, however, due to the noise inside the building, the voice recognition did not seem to work. Therefore, I was unable to gather any beneficial feedback.

<h3 class="single-post-sub-head">Final opinions</h3>

###### Overall, I was really pleased with the final outcome of the project which can be seen at the top of the page. I think that I learnt a lot about Unity development as well as building applications for HoloLens. As well as this, I found the project really fun to build so it was a great experience!

<h3 class="single-post-sub-head">Changes</h3>

###### Given more time, I would have liked to change the victory and defeat sections of the game as they were a little rushed. As well as this, it would have been better to use a different enemy movement system as the enemies can move through the towers that the user places down which makes the game look a little underdeveloped.

<h3 class="single-post-sub-head">Future Plans</h3>

###### In future, I would like to add a few more tower types, tower upgrades and different enemies. This would really help to flesh out the game and massively improve player enjoyment!n I think that I will continue to work on this project over the summer and potentially ship it the Microsoft Store.

###### See the code on [GitHub](https://github.com/Reconkiwi/Football-Wordpress-Theme)
###### Download the visual studio files on [GitHub](https://github.com/Reconkiwi/Football-Wordpress-Theme)

<h3 class="single-post-sub-head">Useful Links</h3>

###### Here are a few useful links that I used to get up and running

* https://www.youtube.com/watch?v=beuoNuK2tbk&list=PLPV2KyIb3jR4u5jX8za5iU1cqnQPmbzG0
- https://docs.microsoft.com/en-us/windows/mixed-reality/install-the-tools
+ https://www.youtube.com/watch?v=ZeeJLsEXjno
- https://www.youtube.com/watch?v=wS2LBCcnSQs&list=PLX-uZVK_0K_4uNwvKian1bscP9mVvOp1M&index=2
+ https://www.youtube.com/watch?v=1zN_9UHKgws
- https://unity3d.com/partners/microsoft/mixed-reality
+ https://github.com/Microsoft/MixedRealityToolkit-Unity
- https://medium.freecodecamp.org/how-to-create-your-first-hololens-app-with-unity-1afa364843d4

<h3 class="single-post-sub-head">NLT</h3>

<a href="NLT2_Document_Ben_Goodwin.docx">Download the NTL HERE!</a>
